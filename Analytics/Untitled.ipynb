{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92c6f9db-4418-4fc1-8d4e-ded3c4971bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 1: Libraries imported ---\n",
      "--- Step 2: Database connection successful! ---\n",
      "\n",
      "--- Step 3: Fetched Raw Customer Data ---\n",
      "    CustID  order_frequency  total_spent  average_spend  days_since_last_order\n",
      "0  C25-005                3       1577.5     525.833333                      0\n",
      "1  C25-006                2       1325.0     662.500000                      7\n",
      "2  C25-007                3       1579.0     526.333333                      0\n",
      "3  C25-008                1        312.0     312.000000                      3\n",
      "4  C25-009                1        840.0     840.000000                      2\n",
      "\n",
      "--- Step 4: Preparing data for clustering ---\n",
      "Data scaled successfully.\n",
      "\n",
      "--- Step 5: Performing K-Means clustering ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juriel\\AppData\\Local\\Temp\\ipykernel_22456\\1693751035.py:50: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, db)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering complete.\n",
      "\n",
      "--- Step 6: Cluster Analysis (Averages) ---\n",
      "         order_frequency  total_spent  average_spend  days_since_last_order\n",
      "cluster                                                                    \n",
      "0                    3.0      1578.25     526.083333                    0.0\n",
      "2                    2.0      1325.00     662.500000                    7.0\n",
      "1                    1.0       727.50     727.500000                    1.5\n",
      "3                    1.0       312.00     312.000000                    3.0\n",
      "\n",
      "Segment names assigned:\n",
      "    CustID         segment_name\n",
      "0  C25-005  High-Value Spenders\n",
      "1  C25-006       Loyal Regulars\n",
      "2  C25-007  High-Value Spenders\n",
      "3  C25-008    New or Occasional\n",
      "4  C25-009    New or Occasional\n",
      "\n",
      "--- Step 7: Saving results to the database ---\n",
      "'Customer_Segments' table ready.\n",
      "✅ Successfully updated segments for 6 customers in the database.\n"
     ]
    }
   ],
   "source": [
    "# This notebook connects to the LaundroLink database, analyzes customer behavior,\n",
    "# groups customers into segments using K-Means clustering, and saves the\n",
    "# results back to the database for the web dashboards to use.\n",
    "\n",
    "# --- 1. Import Libraries ---\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import mysql.connector\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "print(\"--- Step 1: Libraries imported ---\")\n",
    "\n",
    "# --- 2. Database Connection ---\n",
    "# Load database credentials securely from your .env file\n",
    "# This assumes your .env file is in the parent 'Backend' folder\n",
    "try:\n",
    "    load_dotenv('../Backend/.env') \n",
    "    db = mysql.connector.connect(\n",
    "        host=os.getenv(\"DB_HOST\"),\n",
    "        user=os.getenv(\"DB_USER\"),\n",
    "        password=os.getenv(\"DB_PASSWORD\"),\n",
    "        database=os.getenv(\"DB_NAME\")\n",
    "    )\n",
    "    print(\"--- Step 2: Database connection successful! ---\")\n",
    "except mysql.connector.Error as err:\n",
    "    print(f\"--- ❌ Step 2 FAILED: Error connecting to database: {err} ---\")\n",
    "    # Stop execution if the database connection fails\n",
    "    exit()\n",
    "\n",
    "# --- 3. Fetch Customer Behavior Data ---\n",
    "# This query gathers all the raw data we need to understand customer behavior.\n",
    "# It only includes customers who have at least one paid invoice.\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "    c.CustID,\n",
    "    COUNT(DISTINCT o.OrderID) AS order_frequency,\n",
    "    SUM(i.PayAmount) AS total_spent,\n",
    "    AVG(i.PayAmount) AS average_spend,\n",
    "    DATEDIFF(NOW(), MAX(o.OrderCreatedAt)) as days_since_last_order\n",
    "FROM Customer c\n",
    "JOIN Orders o ON c.CustID = o.CustID\n",
    "JOIN Invoice i ON o.OrderID = i.OrderID\n",
    "WHERE i.InvoiceID IN (SELECT InvoiceID FROM Invoice_Status WHERE InvoiceStatus = 'Paid')\n",
    "GROUP BY c.CustID\n",
    "HAVING order_frequency > 0;\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(query, db)\n",
    "print(\"\\n--- Step 3: Fetched Raw Customer Data ---\")\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "# --- 4. Data Preparation for Clustering ---\n",
    "# We need to prepare the data so the clustering algorithm can understand it.\n",
    "print(\"\\n--- Step 4: Preparing data for clustering ---\")\n",
    "\n",
    "# Select only the numerical features for clustering\n",
    "features = df[['order_frequency', 'total_spent', 'average_spend', 'days_since_last_order']]\n",
    "\n",
    "# Scale the data. This is crucial for K-Means to work correctly.\n",
    "# It ensures that one feature (like total_spent) doesn't dominate the others.\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "print(\"Data scaled successfully.\")\n",
    "\n",
    "\n",
    "# --- 5. Perform K-Means Clustering ---\n",
    "# We'll group the customers into 4 segments.\n",
    "print(\"\\n--- Step 5: Performing K-Means clustering ---\")\n",
    "kmeans = KMeans(n_clusters=4, random_state=42, n_init=10)\n",
    "df['cluster'] = kmeans.fit_predict(scaled_features)\n",
    "print(\"Clustering complete.\")\n",
    "\n",
    "\n",
    "# --- 6. Analyze and Name the Segments ---\n",
    "# Let's analyze the characteristics of each cluster to give them meaningful names.\n",
    "cluster_analysis = df.groupby('cluster')[['order_frequency', 'total_spent', 'average_spend', 'days_since_last_order']].mean().sort_values('total_spent', ascending=False)\n",
    "print(\"\\n--- Step 6: Cluster Analysis (Averages) ---\")\n",
    "print(cluster_analysis)\n",
    "\n",
    "# Based on the analysis, we can define our segment names.\n",
    "# This logic dynamically assigns names based on spending and recency.\n",
    "cluster_map = {}\n",
    "sorted_clusters = cluster_analysis.reset_index()\n",
    "\n",
    "cluster_map[sorted_clusters.loc[0, 'cluster']] = 'High-Value Spenders'\n",
    "cluster_map[sorted_clusters.loc[1, 'cluster']] = 'Loyal Regulars'\n",
    "\n",
    "# Find the cluster with the highest days_since_last_order\n",
    "at_risk_cluster = sorted_clusters.sort_values('days_since_last_order', ascending=False).iloc[0]['cluster']\n",
    "if at_risk_cluster not in cluster_map:\n",
    "    cluster_map[at_risk_cluster] = 'At-Risk Customers'\n",
    "\n",
    "# The remaining cluster is 'New or Occasional'\n",
    "for i in range(4):\n",
    "    if i not in cluster_map:\n",
    "        cluster_map[i] = 'New or Occasional'\n",
    "\n",
    "df['segment_name'] = df['cluster'].map(cluster_map)\n",
    "print(\"\\nSegment names assigned:\")\n",
    "print(df[['CustID', 'segment_name']].head())\n",
    "\n",
    "\n",
    "# --- 7. Save Results Back to the Database ---\n",
    "# We'll create a new table to store our results.\n",
    "print(\"\\n--- Step 7: Saving results to the database ---\")\n",
    "cursor = db.cursor()\n",
    "\n",
    "# Create the new table if it doesn't exist\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS Customer_Segments (\n",
    "    CustID VARCHAR(10) PRIMARY KEY,\n",
    "    SegmentName VARCHAR(50),\n",
    "    AnalyzedAt TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,\n",
    "    FOREIGN KEY (CustID) REFERENCES Customer(CustID) ON DELETE CASCADE\n",
    ");\n",
    "\"\"\")\n",
    "print(\"'Customer_Segments' table ready.\")\n",
    "\n",
    "# Insert or update the results for each customer\n",
    "for index, row in df.iterrows():\n",
    "    cursor.execute(\"REPLACE INTO Customer_Segments (CustID, SegmentName) VALUES (%s, %s)\", (row['CustID'], row['segment_name']))\n",
    "\n",
    "db.commit()\n",
    "print(f\"✅ Successfully updated segments for {len(df)} customers in the database.\")\n",
    "\n",
    "# Close the database connection\n",
    "cursor.close()\n",
    "db.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d442f6d3-0686-454d-bb2a-646acb2c7a96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
